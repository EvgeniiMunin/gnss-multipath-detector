{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import keras_metrics as km # for precsion/ recall metrics\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint # to save best model\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for openvino\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from data_generator_sx3 import SX3Dataset\n",
    "from data_generator import CorrDatasetV2\n",
    "from model import Model\n",
    "from utils import save_model#, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% prepare sx3 data (only module)\n",
    "dataset_mp = SX3Dataset(label=1, global_path='sx3_data/outputs/mp')\n",
    "dataset_nomp = SX3Dataset(label=0, global_path='sx3_data/outputs/no_mp')\n",
    "\n",
    "data_mp = dataset_mp.build()\n",
    "data_nomp = dataset_nomp.build()[:500]\n",
    "\n",
    "dataset = np.concatenate((data_mp, data_nomp), axis=0)\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "data_train, data_val = train_test_split(dataset, test_size=0.2)\n",
    "\n",
    "# 1 channel image (only module), add newaxis\n",
    "X_train_sx = np.array([x['table'] for x in data_train])\n",
    "X_val_sx = np.array([x['table'] for x in data_val])\n",
    "\n",
    "y_train_sx = np.array([x['label'] for x in data_train])\n",
    "y_val_sx = np.array([x['label'] for x in data_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((176, 40, 40, 2), (44, 40, 40, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shapes\n",
    "X_train_sx.shape, X_val_sx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% prepare data generator data (only module)\n",
    "global_path_mp_i = 'synth_data/mp/*_i_*'\n",
    "global_path_mp_q = 'synth_data/mp/*_q_*'\n",
    "global_path_nomp_i = 'synth_data/no_mp/*_i_*'\n",
    "global_path_nomp_q = 'synth_data/no_mp/*_q_*'\n",
    "paths_mp_i = sorted(glob.glob(global_path_mp_i))\n",
    "paths_mp_q = sorted(glob.glob(global_path_mp_q))\n",
    "paths_nomp_i = sorted(glob.glob(global_path_nomp_i))\n",
    "paths_nomp_q = sorted(glob.glob(global_path_nomp_q))\n",
    "\n",
    "synth_data_samples = []\n",
    "synth_data_labels = []\n",
    "for path_mp_i, path_mp_q in zip(paths_mp_i, paths_mp_q):\n",
    "    matr_i = pd.read_csv(path_mp_i, sep=',', header=None).values\n",
    "    matr_q = pd.read_csv(path_mp_q, sep=',', header=None).values\n",
    "    matr_i = matr_i[...,None]\n",
    "    matr_q = matr_q[...,None]\n",
    "    matr = np.concatenate((matr_i, matr_q), axis=2)\n",
    "    #matr = matr_i**2 + matr_q**2\n",
    "    synth_data_samples.append(matr)\n",
    "    synth_data_labels.append(1)\n",
    "    \n",
    "for path_nomp_i, path_nomp_q in zip(paths_nomp_i, paths_nomp_q):\n",
    "    matr_i = pd.read_csv(path_nomp_i, sep=',', header=None).values\n",
    "    matr_q = pd.read_csv(path_nomp_q, sep=',', header=None).values\n",
    "    matr_i = matr_i[...,None]\n",
    "    matr_q = matr_q[...,None]\n",
    "    matr = np.concatenate((matr_i, matr_q), axis=2)\n",
    "    #matr = matr_i**2 + matr_q**2\n",
    "    synth_data_samples.append(matr)\n",
    "    synth_data_labels.append(0)\n",
    "\n",
    "synth_data_samples = np.array(synth_data_samples)\n",
    "synth_data_labels = np.array(synth_data_labels)\n",
    "\n",
    "X_train_synth, X_val_synth, y_train_synth, y_val_synth = train_test_split(synth_data_samples, synth_data_labels, test_size=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build, train, save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_9:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fn\n"
     ]
    }
   ],
   "source": [
    "#%% Define model.\n",
    "model = Model(shape=(X_train_synth.shape[1], X_train_synth.shape[2], X_train_synth.shape[3]))\n",
    "\n",
    "batch_size = 8\n",
    "train_iters = 10\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model.model.compile(loss='binary_crossentropy',\n",
    "\t\t\t\t\toptimizer=optimizers.Adam(lr=learning_rate),\n",
    "\t\t\t\t\tmetrics=['acc',\n",
    "\t\t\t\t\t\t   km.binary_precision(),\n",
    "\t\t\t\t\t\t   km.binary_recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from .h5\n",
    "#model.model = load_model('saved_models/sc1_data_gen_train.pkl')\n",
    "#model.model = load_model('saved_models/sc2_fine_tune.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 120 samples\n",
      "Epoch 1/10\n",
      "480/480 [==============================] - 5s 10ms/step - loss: 0.6913 - acc: 0.5208 - precision: 0.5126 - recall: 0.8755 - val_loss: 0.6849 - val_acc: 0.6833 - val_precision: 0.9162 - val_recall: 0.4019\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68491, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.6809 - acc: 0.5604 - precision: 0.5629 - recall: 0.8003 - val_loss: 0.6759 - val_acc: 0.4500 - val_precision: 0.4898 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68491 to 0.67591, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.6554 - acc: 0.6354 - precision: 0.5509 - recall: 0.9809 - val_loss: 0.6335 - val_acc: 0.6917 - val_precision: 0.7414 - val_recall: 0.7045\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67591 to 0.63349, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.6121 - acc: 0.6812 - precision: 0.6696 - recall: 0.5418 - val_loss: 0.5685 - val_acc: 0.7583 - val_precision: 0.8527 - val_recall: 0.6523\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63349 to 0.56853, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.5424 - acc: 0.7833 - precision: 0.8583 - recall: 0.7380 - val_loss: 0.5186 - val_acc: 0.7833 - val_precision: 0.7552 - val_recall: 0.8827\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56853 to 0.51861, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.4562 - acc: 0.8167 - precision: 0.7747 - recall: 0.7810 - val_loss: 0.3957 - val_acc: 0.9000 - val_precision: 0.9575 - val_recall: 0.8260\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.51861 to 0.39575, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 4s 8ms/step - loss: 0.3743 - acc: 0.8729 - precision: 0.9005 - recall: 0.8153 - val_loss: 0.3354 - val_acc: 0.8833 - val_precision: 0.9113 - val_recall: 0.8609\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39575 to 0.33535, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 4s 9ms/step - loss: 0.2982 - acc: 0.8958 - precision: 0.9538 - recall: 0.8614 - val_loss: 0.2720 - val_acc: 0.9167 - val_precision: 0.9593 - val_recall: 0.8609\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33535 to 0.27195, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 4s 9ms/step - loss: 0.2499 - acc: 0.9146 - precision: 0.9680 - recall: 0.8908 - val_loss: 0.2136 - val_acc: 0.9333 - val_precision: 0.9939 - val_recall: 0.8609\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.27195 to 0.21360, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 4s 9ms/step - loss: 0.1993 - acc: 0.9417 - precision: 0.9825 - recall: 0.8961 - val_loss: 0.1696 - val_acc: 0.9333 - val_precision: 1.0000 - val_recall: 0.8299\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.21360 to 0.16956, saving model to saved_models/best_model/best_mp_model.h5\n"
     ]
    }
   ],
   "source": [
    "# train model, sae best weigths with checkpointer\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/best_model/best_mp_model.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "#%% Train model: pretrain on data gen\n",
    "history = model.model.fit(\n",
    "    x=X_train_synth,\n",
    "    y=y_train_synth,\n",
    "    validation_data=(X_val_synth, y_val_synth),\n",
    "    epochs=train_iters,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[checkpointer]\n",
    "    )\n",
    "#save_model(model.model, 'saved_models/sc1_data_gen_train_zoom.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Keras model .h5 to TF frozen graph .pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_14:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_15:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_16:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_17:0' shape=() dtype=int32> fn\n",
      "WARNING:tensorflow:From <ipython-input-25-83715c089b2f>:18: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 292 variables.\n",
      "INFO:tensorflow:Converted 292 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'saved_models/tf_model/tf_mp_model.pb'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras to tf conversion\n",
    "\n",
    "keras_model_path = 'saved_models/best_model/best_mp_model.h5'\n",
    "\n",
    "# freeze state of a session into a pruned compilation graph\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = ''\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def, \n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "    \n",
    "# loading keras model\n",
    "K.set_learning_phase(0)\n",
    "model = load_model(keras_model_path,\n",
    "                  custom_objects={\n",
    "                      'binary_precision': km.binary_precision(),\n",
    "                      'binary_recall': km.binary_recall()\n",
    "                  })\n",
    "\n",
    "# create frozen graph of the keras model\n",
    "frozen_graph = freeze_session(K.get_session(), \n",
    "                              output_names=[out.op.name for out in model.outputs])\n",
    "\n",
    "# save model as .pb file\n",
    "tf.train.write_graph(frozen_graph, 'saved_models/tf_model', 'tf_mp_model.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert TF .pb to IR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/evgenii/Documents/01_These/gnss_signal_generator/saved_models/tf_model/tf_mp_model.pb\n",
      "\t- Path for generated IR: \t/home/evgenii/Documents/01_These/gnss_signal_generator/saved_models/ir_model\n",
      "\t- IR output name: \tir_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,40,40,2]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2019.3.0-408-gac8584cb7\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/evgenii/Documents/01_These/gnss_signal_generator/saved_models/ir_model/ir_model.xml\n",
      "[ SUCCESS ] BIN file: /home/evgenii/Documents/01_These/gnss_signal_generator/saved_models/ir_model/ir_model.bin\n",
      "[ SUCCESS ] Total execution time: 13.15 seconds. \n"
     ]
    }
   ],
   "source": [
    "# convert tensorflow graph to ir_model (from terminal or bash)\n",
    "! chmod 744 convert_tf_ncs2.sh\n",
    "! ./convert_tf_ncs2.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make inference on NCS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 40, 2)\n",
      "(1, 2, 40, 40)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sx[0].shape)\n",
    "prepimg = np.ndarray(shape=(n,c,h,w))\n",
    "prepimg[0, 0, :,:] = np.moveaxis(X_train_sx[0], -1, 0)[0,:]\n",
    "print(prepimg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.moveaxis(X_train_sx[0], -1, 0)[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] loading network files: \n",
      "\tsaved_models/ir_model/ir_model.xml\n",
      "\tsaved_models/ir_model/ir_model.bin\n",
      "[ INFO ] Preparing input blobs\n",
      "[ INFO ] required img shape:  1,2,40,40\n",
      "[ INFO ] prepimg shape:  1,2,40,40\n"
     ]
    }
   ],
   "source": [
    "# run inference on NCS2\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import logging as log\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "log.basicConfig(format='[ %(levelname)s ] %(message)s', level=log.INFO, stream=sys.stdout)\n",
    "model_xml_path = 'saved_models/ir_model/ir_model.xml'\n",
    "model_bin_path = 'saved_models/ir_model/ir_model.bin'\n",
    "\n",
    "# plugin initialization for specified device\n",
    "plugin = IEPlugin(device='MYRIAD')\n",
    "\n",
    "# read ir model\n",
    "log.info('loading network files: \\n\\t{}\\n\\t{}'.format(model_xml_path, model_bin_path))\n",
    "net = IENetwork(model=model_xml_path, weights=model_bin_path)\n",
    "\n",
    "log.info('Preparing input blobs')\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "\n",
    "# prepare image\n",
    "# get shapes\n",
    "n, c, h, w = net.inputs[input_blob].shape\n",
    "log.info('required img shape:  {},{},{},{}'.format(n, c, h, w))\n",
    "prepimg = np.ndarray(shape=(n, c, h, w))\n",
    "\n",
    "# change data layout from HW to NCHW\n",
    "prepimg[0,0,:,:] = np.moveaxis(X_train_sx[0], -1, 0)[0,:]\n",
    "log.info('prepimg shape:  {},{},{},{}'.format(prepimg.shape[0], prepimg.shape[1], prepimg.shape[2], prepimg.shape[3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Loading model to the plugin\n",
      "[ INFO ] Starting inference (1 iterations)\n"
     ]
    }
   ],
   "source": [
    "# loading model to plugin\n",
    "log.info('Loading model to the plugin')\n",
    "exec_net = plugin.load(network=net)\n",
    "del net\n",
    "\n",
    "# start sync inference\n",
    "log.info('Starting inference ({} iterations)'.format(1))\n",
    "infer_time = []\n",
    "t0 = time()\n",
    "res = exec_net.infer(inputs={input_blob: prepimg})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openvino.inference_engine.ie_api.ExecutableNetwork at 0x7f7b700efc80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Average running time of one iteration: 21335.390329360962 ms\n"
     ]
    }
   ],
   "source": [
    "infer_time.append((time() - t0) * 1000)\n",
    "log.info('Average running time of one iteration: {} ms'.format(np.average(np.asarray(infer_time))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Processing output blob\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "# processing output blob\n",
    "log.info('Processing output blob')\n",
    "res = res[out_blob]\n",
    "print(res)\n",
    "\n",
    "del exec_net\n",
    "del plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
