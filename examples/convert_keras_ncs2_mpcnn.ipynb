{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import keras_metrics as km # for precsion/ recall metrics\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint # to save best model\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for openvino\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from data_generator_sx3 import SX3Dataset\n",
    "from data_generator import CorrDatasetV2\n",
    "from model import Model\n",
    "from utils import save_model#, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% prepare sx3 data (only module)\n",
    "dataset_mp = SX3Dataset(label=1, global_path='sx3_data/outputs/mp')\n",
    "dataset_nomp = SX3Dataset(label=0, global_path='sx3_data/outputs/no_mp')\n",
    "\n",
    "data_mp = dataset_mp.build()\n",
    "data_nomp = dataset_nomp.build()[:500]\n",
    "\n",
    "dataset = np.concatenate((data_mp, data_nomp), axis=0)\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "data_train, data_val = train_test_split(dataset, test_size=0.2)\n",
    "\n",
    "# 1 channel image (only module), add newaxis\n",
    "X_train_sx = np.array([x['table'] for x in data_train])\n",
    "X_val_sx = np.array([x['table'] for x in data_val])\n",
    "\n",
    "y_train_sx = np.array([x['label'] for x in data_train])\n",
    "y_val_sx = np.array([x['label'] for x in data_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((176, 40, 40, 2), (44, 40, 40, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shapes\n",
    "X_train_sx.shape, X_val_sx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% prepare data generator data (only module)\n",
    "global_path_mp_i = 'synth_data/mp/*_i_*'\n",
    "global_path_mp_q = 'synth_data/mp/*_q_*'\n",
    "global_path_nomp_i = 'synth_data/no_mp/*_i_*'\n",
    "global_path_nomp_q = 'synth_data/no_mp/*_q_*'\n",
    "paths_mp_i = sorted(glob.glob(global_path_mp_i))\n",
    "paths_mp_q = sorted(glob.glob(global_path_mp_q))\n",
    "paths_nomp_i = sorted(glob.glob(global_path_nomp_i))\n",
    "paths_nomp_q = sorted(glob.glob(global_path_nomp_q))\n",
    "\n",
    "synth_data_samples = []\n",
    "synth_data_labels = []\n",
    "for path_mp_i, path_mp_q in zip(paths_mp_i, paths_mp_q):\n",
    "    matr_i = pd.read_csv(path_mp_i, sep=',', header=None).values\n",
    "    matr_q = pd.read_csv(path_mp_q, sep=',', header=None).values\n",
    "    matr_i = matr_i[...,None]\n",
    "    matr_q = matr_q[...,None]\n",
    "    matr = np.concatenate((matr_i, matr_q), axis=2)\n",
    "    #matr = matr_i**2 + matr_q**2\n",
    "    synth_data_samples.append(matr)\n",
    "    synth_data_labels.append(1)\n",
    "    \n",
    "for path_nomp_i, path_nomp_q in zip(paths_nomp_i, paths_nomp_q):\n",
    "    matr_i = pd.read_csv(path_nomp_i, sep=',', header=None).values\n",
    "    matr_q = pd.read_csv(path_nomp_q, sep=',', header=None).values\n",
    "    matr_i = matr_i[...,None]\n",
    "    matr_q = matr_q[...,None]\n",
    "    matr = np.concatenate((matr_i, matr_q), axis=2)\n",
    "    #matr = matr_i**2 + matr_q**2\n",
    "    synth_data_samples.append(matr)\n",
    "    synth_data_labels.append(0)\n",
    "\n",
    "synth_data_samples = np.array(synth_data_samples)\n",
    "synth_data_labels = np.array(synth_data_labels)\n",
    "\n",
    "X_train_synth, X_val_synth, y_train_synth, y_val_synth = train_test_split(synth_data_samples, synth_data_labels, test_size=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build, train, save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_iters = 20\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_4:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_5:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_6:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_7:0' shape=() dtype=int32> fn\n"
     ]
    }
   ],
   "source": [
    "#%% Define model.\n",
    "model = Model(shape=(X_train_sx.shape[1], X_train_sx.shape[2], X_train_sx.shape[3]))\n",
    "\n",
    "model.model.compile(loss='binary_crossentropy',\n",
    "\t\t\t\t\toptimizer=optimizers.Adam(lr=learning_rate),\n",
    "\t\t\t\t\tmetrics=['acc',\n",
    "\t\t\t\t\t\t   km.binary_precision(),\n",
    "\t\t\t\t\t\t   km.binary_recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 38, 38, 16)        304       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 36, 36, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 418,433\n",
      "Trainable params: 418,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
      "  warnings.warn('`Sequential.model` is deprecated. '\n"
     ]
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from .h5\n",
    "#model.model = load_model('saved_models/sc1_data_gen_train.pkl')\n",
    "#model.model = load_model('saved_models/sc2_fine_tune.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "[ WARNING ] From /home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 3s 33ms/step - loss: 0.7006 - acc: 0.4875 - precision: 0.6325 - recall: 0.7441 - val_loss: 0.7069 - val_acc: 0.4000 - val_precision: 0.4875 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70691, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.6869 - acc: 0.5375 - precision: 0.5148 - recall: 1.0000 - val_loss: 0.7004 - val_acc: 0.4000 - val_precision: 0.4875 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.70691 to 0.70042, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.6807 - acc: 0.6500 - precision: 0.6172 - recall: 1.0000 - val_loss: 0.6963 - val_acc: 0.4500 - val_precision: 0.5042 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.70042 to 0.69626, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.6708 - acc: 0.7000 - precision: 0.6433 - recall: 1.0000 - val_loss: 0.6899 - val_acc: 0.5000 - val_precision: 0.5529 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.69626 to 0.68989, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6589 - acc: 0.7000 - precision: 0.6132 - recall: 0.9115 - val_loss: 0.6803 - val_acc: 0.5500 - val_precision: 0.5744 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.68989 to 0.68031, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6419 - acc: 0.7500 - precision: 0.7017 - recall: 0.9295 - val_loss: 0.6773 - val_acc: 0.5000 - val_precision: 0.5529 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68031 to 0.67732, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.6218 - acc: 0.7625 - precision: 0.6378 - recall: 0.9707 - val_loss: 0.6536 - val_acc: 0.6000 - val_precision: 0.5992 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.67732 to 0.65361, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.5958 - acc: 0.7875 - precision: 0.7405 - recall: 0.9976 - val_loss: 0.6300 - val_acc: 0.6500 - val_precision: 0.6103 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.65361 to 0.63004, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.5628 - acc: 0.8125 - precision: 0.7088 - recall: 0.9528 - val_loss: 0.6342 - val_acc: 0.5500 - val_precision: 0.5744 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.63004\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.5301 - acc: 0.8125 - precision: 0.7056 - recall: 0.9976 - val_loss: 0.5764 - val_acc: 0.6500 - val_precision: 0.6573 - val_recall: 0.9107\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.63004 to 0.57640, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4994 - acc: 0.8000 - precision: 0.7713 - recall: 0.9749 - val_loss: 0.5379 - val_acc: 0.7500 - val_precision: 0.7121 - val_recall: 0.9107\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.57640 to 0.53792, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4669 - acc: 0.8750 - precision: 0.8770 - recall: 0.8474 - val_loss: 0.5604 - val_acc: 0.6500 - val_precision: 0.5954 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.53792\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.4343 - acc: 0.8375 - precision: 0.7061 - recall: 0.9426 - val_loss: 0.5045 - val_acc: 0.7500 - val_precision: 0.7677 - val_recall: 0.9107\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.53792 to 0.50449, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.3951 - acc: 0.8750 - precision: 0.8819 - recall: 0.9262 - val_loss: 0.4871 - val_acc: 0.7500 - val_precision: 0.7677 - val_recall: 0.9107\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.50449 to 0.48712, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3615 - acc: 0.9250 - precision: 0.8905 - recall: 0.9271 - val_loss: 0.4727 - val_acc: 0.7500 - val_precision: 0.7677 - val_recall: 0.9107\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.48712 to 0.47273, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3288 - acc: 0.9125 - precision: 0.9359 - recall: 0.9040 - val_loss: 0.4978 - val_acc: 0.7500 - val_precision: 0.7677 - val_recall: 0.9107\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.47273\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.3067 - acc: 0.9125 - precision: 0.9383 - recall: 0.8829 - val_loss: 0.3913 - val_acc: 0.8000 - val_precision: 0.8167 - val_recall: 0.9107\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.47273 to 0.39128, saving model to saved_models/best_model/best_mp_model.h5\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.2998 - acc: 0.9125 - precision: 0.9504 - recall: 0.8618 - val_loss: 0.5577 - val_acc: 0.6500 - val_precision: 0.6500 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.39128\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2841 - acc: 0.8750 - precision: 0.8573 - recall: 0.9605 - val_loss: 0.4069 - val_acc: 0.8000 - val_precision: 0.8167 - val_recall: 0.9107\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.39128\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.2569 - acc: 0.9375 - precision: 0.9266 - recall: 0.9173 - val_loss: 0.5275 - val_acc: 0.7500 - val_precision: 0.7506 - val_recall: 1.0000\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.39128\n"
     ]
    }
   ],
   "source": [
    "# train model, sae best weigths with checkpointer\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/best_model/best_mp_model.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "#%% Train model: pretrain on data gen\n",
    "history = model.model.fit(\n",
    "    x=X_train_sx,\n",
    "    y=y_train_sx,\n",
    "    validation_data=(X_val_sx, y_val_sx),\n",
    "    epochs=train_iters,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[checkpointer]\n",
    "    )\n",
    "#save_model(model.model, 'saved_models/sc1_data_gen_train_zoom.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step\n",
      "(20, 1) [[0.4967223 ]\n",
      " [0.965235  ]\n",
      " [0.97178495]\n",
      " [0.24136654]\n",
      " [0.9409014 ]\n",
      " [0.9676019 ]\n",
      " [0.4022568 ]\n",
      " [0.9923723 ]\n",
      " [0.62924707]\n",
      " [0.24136034]]\n",
      "(20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([0]), 0),\n",
       " (array([1]), 1),\n",
       " (array([1]), 1),\n",
       " (array([0]), 0),\n",
       " (array([1]), 1),\n",
       " (array([1]), 1),\n",
       " (array([0]), 0),\n",
       " (array([1]), 1),\n",
       " (array([1]), 0),\n",
       " (array([0]), 0)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model predicts probas\n",
    "pred_probas = model.model.predict(\n",
    "                    x=X_val_sx,\n",
    "                    verbose=1\n",
    "                    )\n",
    "print(pred_probas.shape, pred_probas[:10])\n",
    "\n",
    "# convert probas into labels\n",
    "preds = (pred_probas > 0.5).astype(int)\n",
    "print(preds.shape)\n",
    "list(zip(preds[:10], y_val_sx[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Keras model .h5 to TF frozen graph .pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_8:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_9:0' shape=() dtype=int32> fp\n",
      "tracking <tf.Variable 'Variable_10:0' shape=() dtype=int32> tp\n",
      "tracking <tf.Variable 'Variable_11:0' shape=() dtype=int32> fn\n",
      "WARNING:tensorflow:From <ipython-input-42-83715c089b2f>:18: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "[ WARNING ] From <ipython-input-42-83715c089b2f>:18: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "[ WARNING ] From /home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 153 variables.\n",
      "[ INFO ] Froze 153 variables.\n",
      "INFO:tensorflow:Converted 153 variables to const ops.\n",
      "[ INFO ] Converted 153 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'saved_models/tf_model/tf_mp_model.pb'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras to tf conversion\n",
    "\n",
    "keras_model_path = 'saved_models/best_model/best_mp_model.h5'\n",
    "\n",
    "# freeze state of a session into a pruned compilation graph\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = ''\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def, \n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "    \n",
    "# loading keras model\n",
    "K.set_learning_phase(0)\n",
    "model = load_model(keras_model_path,\n",
    "                  custom_objects={\n",
    "                      'binary_precision': km.binary_precision(),\n",
    "                      'binary_recall': km.binary_recall()\n",
    "                  })\n",
    "\n",
    "# create frozen graph of the keras model\n",
    "frozen_graph = freeze_session(K.get_session(), \n",
    "                              output_names=[out.op.name for out in model.outputs])\n",
    "\n",
    "# save model as .pb file\n",
    "tf.train.write_graph(frozen_graph, 'saved_models/tf_model', 'tf_mp_model.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert TF .pb to IR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/evgenii/Documents/01_These/gnss_signal_generator/saved_models/tf_model/tf_mp_model.pb\n",
      "\t- Path for generated IR: \t/home/evgenii/Documents/01_These/gnss_signal_generator/saved_models/ir_model\n",
      "\t- IR output name: \tir_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,40,40,2]\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP16\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2019.3.0-408-gac8584cb7\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/evgenii/Documents/01_These/gnss_signal_generator/saved_models/ir_model/ir_model.xml\n",
      "[ SUCCESS ] BIN file: /home/evgenii/Documents/01_These/gnss_signal_generator/saved_models/ir_model/ir_model.bin\n",
      "[ SUCCESS ] Total execution time: 19.72 seconds. \n"
     ]
    }
   ],
   "source": [
    "# convert tensorflow graph to ir_model (from terminal or bash)\n",
    "! chmod 744 convert_tf_ncs2.sh\n",
    "! ./convert_tf_ncs2.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make inference on NCS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dimensions/ indices\n",
    "#print(X_train_sx[0].shape)\n",
    "#prepimg = np.ndarray(shape=(n,c,h,w))\n",
    "#prepimg[0, 0, :,:] = np.moveaxis(X_train_sx[0], -1, 0)[0,:]\n",
    "#print(prepimg.shape)\n",
    "\n",
    "#np.moveaxis(X_train_sx[0], -1, 0)[0,:].shape\n",
    "#ind = np.random.choice(range(X_train_sx.shape[0]))\n",
    "#ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] loading network files: \n",
      "\tsaved_models/ir_model/ir_model.xml\n",
      "\tsaved_models/ir_model/ir_model.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'conv2d_5_input_1': <openvino.inference_engine.ie_api.InputInfo at 0x7f712d4e2ab0>},\n",
       " {'dense_4_1/Sigmoid': <openvino.inference_engine.ie_api.OutputInfo at 0x7f712d4e2c30>})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plugin initialization for specified device\n",
    "plugin = IEPlugin(device='MYRIAD')\n",
    "\n",
    "# read ir model\n",
    "log.info('loading network files: \\n\\t{}\\n\\t{}'.format(model_xml_path, model_bin_path))\n",
    "net = IENetwork(model=model_xml_path, weights=model_bin_path)\n",
    "net.inputs, net.outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] loading network files: \n",
      "\tsaved_models/ir_model/ir_model.xml\n",
      "\tsaved_models/ir_model/ir_model.bin\n",
      "[ INFO ] Preparing input blobs\n",
      "[ INFO ] required img shape:  1,2,40,40\n",
      "[ INFO ] prepimg shape:  1,2,40,40\n",
      "[ INFO ] Loading model to the plugin\n",
      "[ INFO ] Starting inference (1 iterations)\n",
      "[ INFO ] Average running time of one iteration: 6.914854049682617 ms\n",
      "[ INFO ] Processing output blob\n",
      "compare pred:  28 [[1.]] [[1]] 1\n"
     ]
    }
   ],
   "source": [
    "# run inference on NCS2\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import logging as log\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "log.basicConfig(format='[ %(levelname)s ] %(message)s', level=log.INFO, stream=sys.stdout)\n",
    "model_xml_path = 'saved_models/ir_model/ir_model.xml' # model\n",
    "model_bin_path = 'saved_models/ir_model/ir_model.bin' # weights\n",
    "\n",
    "# plugin initialization for specified device\n",
    "plugin = IEPlugin(device='MYRIAD')\n",
    "\n",
    "# read ir model\n",
    "log.info('loading network files: \\n\\t{}\\n\\t{}'.format(model_xml_path, model_bin_path))\n",
    "net = IENetwork(model=model_xml_path, weights=model_bin_path)\n",
    "\n",
    "log.info('Preparing input blobs')\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "\n",
    "# prepare image\n",
    "# get shapes\n",
    "n, c, h, w = net.inputs[input_blob].shape\n",
    "log.info('required img shape:  {},{},{},{}'.format(n, c, h, w))\n",
    "prepimg = np.ndarray(shape=(n, c, h, w))\n",
    "\n",
    "# change data layout from HW to NCHW\n",
    "ind = np.random.choice(range(X_train_sx.shape[0]))\n",
    "prepimg[0,0,:,:] = np.moveaxis(X_train_sx[ind], -1, 0)[0,:]\n",
    "log.info('prepimg shape:  {},{},{},{}'.format(prepimg.shape[0], prepimg.shape[1], prepimg.shape[2], prepimg.shape[3]))\n",
    "\n",
    "# loading model to plugin\n",
    "log.info('Loading model to the plugin')\n",
    "exec_net = plugin.load(network=net)\n",
    "del net\n",
    "\n",
    "# start sync inference\n",
    "log.info('Starting inference ({} iterations)'.format(1))\n",
    "infer_time = []\n",
    "t0 = time()\n",
    "res = exec_net.infer(inputs={input_blob: prepimg})\n",
    "\n",
    "infer_time.append((time() - t0) * 1000)\n",
    "log.info('Average running time of one iteration: {} ms'.format(np.average(np.asarray(infer_time))))\n",
    "\n",
    "# processing output blob\n",
    "log.info('Processing output blob')\n",
    "pred_probas = res[out_blob]\n",
    "# convert probas into labels\n",
    "preds = (pred_probas > 0.5).astype(int)\n",
    "#print(ind, pred_probas, preds, y_train_sx[ind])\n",
    "print('compare pred: ', ind, pred_probas, preds, y_train_sx[ind])\n",
    "\n",
    "# del plugin to make inference next time\n",
    "del exec_net\n",
    "del plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('conv2d_5_input_1', 'dense_4_1/Sigmoid')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_blob, out_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 80, 80, 2),\n",
       " (20, 40, 40, 2),\n",
       " array([0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_synth.shape, X_val_sx.shape, y_train_sx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 40, 40) (40, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7190bd8690>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(prepimg.shape, np.moveaxis(X_val_sx[ind], -1, 0)[0,:].shape)\n",
    "plt.imshow(prepimg[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del plugin to make inference next time\n",
    "del exec_net\n",
    "del plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
