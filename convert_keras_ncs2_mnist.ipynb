{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "# for openvino\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: (60000, 28, 28) images <class 'numpy.ndarray'>\n",
      "test data: (10000, 28, 28) images <class 'numpy.ndarray'>\n",
      "train data after: (60000, 28, 28, 1) images <class 'numpy.ndarray'>\n",
      "test data after: (10000, 28, 28, 1) images <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# load mnist dataset\n",
    "from keras.datasets import mnist\n",
    "(x_train_img, y_train_label), (x_test_img, y_test_label) = mnist.load_data()\n",
    "\n",
    "# preview data shape\n",
    "print('train data: {} images'.format(x_train_img.shape), type(x_train_img))\n",
    "print('test data: {} images'.format(x_test_img.shape), type(x_test_img))\n",
    "\n",
    "# reshape (add color channel)\n",
    "x_train_img = x_train_img.reshape(-1, 28, 28, 1)\n",
    "x_test_img = x_test_img.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# check shape\n",
    "print('train data after: {} images'.format(x_train_img.shape), type(x_train_img))\n",
    "print('test data after: {} images'.format(x_test_img.shape), type(x_test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels: (60000, 10) images <class 'numpy.ndarray'>\n",
      "test labels: (10000, 10) images <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# normalize x matrices\n",
    "x_train = x_train_img.astype('float32') / 255\n",
    "x_test = x_test_img.astype('float32') / 255\n",
    "\n",
    "# one hot encode labels\n",
    "y_train = np_utils.to_categorical(y_train_label, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test_label, num_classes=10)\n",
    "\n",
    "print('train labels: {} images'.format(y_train.shape), type(y_train))\n",
    "print('test labels: {} images'.format(y_test.shape), type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 215,370\n",
      "Trainable params: 215,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build keras model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(5,5), padding='same', input_shape=(28,28,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/evgenii/anaconda3/envs/my_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "54000/54000 [==============================] - 99s 2ms/step - loss: 0.4049 - accuracy: 0.8743 - val_loss: 0.0701 - val_accuracy: 0.9793\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07007, saving model to best_model.h5\n",
      "10000/10000 [==============================] - 8s 803us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07475339432712644, 0.9753999710083008]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model, sae best weigths with checkpointer\n",
    "checkpointer = ModelCheckpoint(filepath='best_model.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "train_history = model.fit(x=x_train, y=y_train,\n",
    "                          validation_split=0.1,\n",
    "                         epochs=1,\n",
    "                         batch_size=200,\n",
    "                         verbose=1,\n",
    "                         callbacks=[checkpointer])\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 132 variables.\n",
      "[ INFO ] Froze 132 variables.\n",
      "INFO:tensorflow:Converted 132 variables to const ops.\n",
      "[ INFO ] Converted 132 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tf_model/tf_model.pb'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras to tf conversion\n",
    "keras_model_path = 'best_model.h5'\n",
    "\n",
    "# freeze state of a session into a pruned compilation graph\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = ''\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def, \n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "\n",
    "# loading keras model\n",
    "K.set_learning_phase(0)\n",
    "model = load_model(keras_model_path)\n",
    "\n",
    "# create frozen graph of the keras model\n",
    "frozen_graph = freeze_session(K.get_session(), \n",
    "                              output_names=[out.op.name for out in model.outputs])\n",
    "\n",
    "# save model as .pb file\n",
    "tf.train.write_graph(frozen_graph, 'tf_model', 'tf_model.pb', as_text=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tensorflow graph to ir_model (from terminal or bash)\n",
    "cd /\n",
    "cd opt/intel/openvino_2019.3.376/deployment_tools/model_optimizer/\n",
    "conda activate my_env\n",
    "mo.py --data_type FP16 --framework tf --input_model /home/evgenii/Documents/01_These/keras_ncs2_converter/tf_model/tf_model.pb --model_name ir_model --output_dir /home/evgenii/Documents/01_These/keras_ncs2_converter/ir_model --input_shape [1,28,28,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] loading network files: \n",
      "\tir_model/ir_model.xml\n",
      "\tir_model/ir_model.bin\n",
      "[ INFO ] Preparing input blobs\n",
      "1 1 28 28\n",
      "[ INFO ] Loading model to the plugin\n",
      "[ INFO ] Starting inference (1 iterations)\n",
      "[ INFO ] Average running time of one iteration: 5.878448486328125 ms\n",
      "[ INFO ] Processing output blob\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# run inference on NCS2\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import logging as log\n",
    "from time import time\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "\n",
    "im_path = 'inference_image/6.jpg'\n",
    "\n",
    "log.basicConfig(format='[ %(levelname)s ] %(message)s', level=log.INFO, stream=sys.stdout)\n",
    "model_xml_path = 'ir_model/ir_model.xml'\n",
    "model_bin_path = 'ir_model/ir_model.bin'\n",
    "\n",
    "# plugin initialization for specified device\n",
    "plugin = IEPlugin(device='MYRIAD')\n",
    "\n",
    "# read ir model\n",
    "log.info('loading network files: \\n\\t{}\\n\\t{}'.format(model_xml_path, model_bin_path))\n",
    "net = IENetwork(model=model_xml_path, weights=model_bin_path)\n",
    "\n",
    "log.info('Preparing input blobs')\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "\n",
    "# prepare image\n",
    "# get shapes\n",
    "n, c, h, w = net.inputs[input_blob].shape\n",
    "print(n, c, h, w)\n",
    "prepimg = np.ndarray(shape=(n, c, h, w))\n",
    "\n",
    "# read image as grayscale\n",
    "im = cv2.imread(im_path, 0)\n",
    "\n",
    "# resize image\n",
    "resized_image = cv2.resize(im, (28, 28), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# change data layout from HW to NCHW\n",
    "prepimg[0,0,:,:] = resized_image\n",
    "\n",
    "# loading model to plugin\n",
    "log.info('Loading model to the plugin')\n",
    "exec_net = plugin.load(network=net)\n",
    "del net\n",
    "\n",
    "# start sync inference\n",
    "log.info('Starting inference ({} iterations)'.format(1))\n",
    "infer_time = []\n",
    "t0 = time()\n",
    "res = exec_net.infer(inputs={input_blob: prepimg})\n",
    "infer_time.append((time() - t0) * 1000)\n",
    "log.info('Average running time of one iteration: {} ms'.format(np.average(np.asarray(infer_time))))\n",
    "\n",
    "# processing output blob\n",
    "log.info('Processing output blob')\n",
    "res = res[out_blob]\n",
    "print(res)\n",
    "\n",
    "del exec_net\n",
    "del plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
